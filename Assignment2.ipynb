{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a46b67",
   "metadata": {},
   "source": [
    "# THREE TYPES OF MODELS\n",
    "\n",
    "Linear Regression (Regression)\n",
    "\n",
    "K-Means Clustering (Clustering)\n",
    "\n",
    "Multinomial Naive Bayes (Classification)\n",
    "\n",
    "\n",
    "The data contains two columns,\n",
    "    'text' = the message\n",
    "    'label' = 1 if spam, 0 if not spam (ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd1f6f",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#importing each model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "# evaluation for each model\n",
    "from sklearn.metrics import (\n",
    "    #classification\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    #clustering\n",
    "    silhouette_score,\n",
    "    v_measure_score)\n",
    "\n",
    "# plot data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea91319",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f84d5",
   "metadata": {},
   "source": [
    "### Dataset Loader and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47c59f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    #loads the csv fule at filename e.g (\"MergedDataCleaned.csv\") \n",
    "    dataset = pd.read_csv(filename, encoding='latin-1')\n",
    "\n",
    "    # Our data set has column name of text, spam. Renaming it to make it clearer for later \n",
    "    # waiitng for more data features to be added. so changing it helps\n",
    "    if 'text' in dataset.columns and 'spam' in dataset.columns: # and 'vowel_count' in dataset.columns etc\n",
    "        dataset = dataset.rename(columns={'spam': 'Spam', 'text': 'Message'})\n",
    "\n",
    "    print(\"Dataset Overview:\")\n",
    "\n",
    "    print(f\"Dataset shape: {dataset.shape}\")\n",
    "    print(f\"Available features: {list(dataset.columns)}\")\n",
    "    print(f\"Spam distribution:\\n{dataset['Spam'].value_counts().to_string()}\")\n",
    "    print(f\"Spam percentage: {dataset['Spam'].mean():.2%}\")\n",
    "    \n",
    "    print(\"First 5 rows of dataset:\")\n",
    "    print(dataset.head())\n",
    "    print(\"\\nLast 5 rows of dataset:\") \n",
    "    print(dataset.tail(), '\\n')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea333e",
   "metadata": {},
   "source": [
    "### Train / Test Splitting\n",
    "uses data processed by the load_data func\n",
    "\n",
    "Uses the dataset, to split into training and testing datasets. \n",
    "\n",
    "Using the sklearn split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d30ac363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(data): \n",
    "    X = data['Message']\n",
    "    y = data['Spam']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc53e2b",
   "metadata": {},
   "source": [
    "### Model pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d5b5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification model pipelines\n",
    "def create_logistic_regression_pipeline():\n",
    "    return Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('lr', LogisticRegression(solver='liblinear'))\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_multinomial_naive_bayes_pipeline():\n",
    "    return Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('mnb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "\n",
    "# Cluster model Pipeline\n",
    "def create_kmeans_pipeline():\n",
    "    return Pipeline([\n",
    "        ('count', CountVectorizer(stop_words='english')),\n",
    "        ('km', KMeans(n_clusters=2, random_state=42))\n",
    "    ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0650f",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "915fe01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_lr(X_train, X_test, y_train, y_test):\n",
    "    #Logistic Regression Pipleine Created\n",
    "    clf = create_logistic_regression_pipeline()\n",
    "    \n",
    "    # Trained data using the Logistic Regression pipleline\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #predicts on test data \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    print('Logistic Regression Results')\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Precision:', precision_score(y_test, y_pred))\n",
    "    print('Recall:', recall_score(y_test, y_pred))\n",
    "    print('F1 score:', f1_score(y_test, y_pred), '\\n')\n",
    "    \n",
    "    # return clf, y_pred #if need to use later "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef474e",
   "metadata": {},
   "source": [
    "### Multinomial Naive Beyer Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c6bf5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_mnb(X_train, X_test, y_train, y_test):\n",
    "    #Multinomial Naive Beyer Pipleine Created\n",
    "    clf = create_multinomial_naive_bayes_pipeline()\n",
    "    \n",
    "    # Trained data using the Multinomial Naive Beyer pipleline\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #predicts on test data \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    print('MultinomialNB Results')\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Precision:', precision_score(y_test, y_pred))\n",
    "    print('Recall:', recall_score(y_test, y_pred))\n",
    "    print('F1 score:', f1_score(y_test, y_pred), '\\n')\n",
    "    \n",
    "    # return clf, y_pred #if need to use later "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7520310",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e22f6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_km(dataset):\n",
    "\n",
    "    #K-Means Clustering Pipleine Created\n",
    "    clf = create_kmeans_pipeline()\n",
    "        \n",
    "    # Trained data using the 'Message' column, as it uses unlabeled data for training\n",
    "    clf.fit(dataset['Message'])\n",
    "\n",
    "    #cluster label\n",
    "    cluster_labels = clf.named_steps['km'].labels_ # accesess the cluster labels within K means pipeline\n",
    "    \n",
    "    X_vec = clf.named_steps['count'].transform(dataset['Message'])\n",
    "\n",
    "    # Evaluate predictions\n",
    "    print('K-Means Clustering Results')\n",
    "    print(\"Silhouette Score:\", silhouette_score(X_vec, cluster_labels))\n",
    "\n",
    "    true_labels = dataset['Spam'] # shows the ground truth labels to compare predicted against \n",
    "    print(\"V-Measure Score:\", v_measure_score(true_labels, cluster_labels), '\\n')\n",
    "    \n",
    "    #return clf, dataset\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f170ac",
   "metadata": {},
   "source": [
    "## Final execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa4fdd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Dataset shape: (31671, 2)\n",
      "Available features: ['Message', 'Spam']\n",
      "Spam distribution:\n",
      "Spam\n",
      "0    17934\n",
      "1    13737\n",
      "Spam percentage: 43.37%\n",
      "First 5 rows of dataset:\n",
      "                                             Message  Spam\n",
      "0  we know you would love to see all these wonder...     1\n",
      "1  start date hourahead hour no ancillari schedul...     0\n",
      "2  the deal are all in meter is on deal and meter...     0\n",
      "3  per your phone messag the gri flag ha been cha...     0\n",
      "4  o italiano marco carola e gaetano parisio enca...     1\n",
      "\n",
      "Last 5 rows of dataset:\n",
      "                                                 Message  Spam\n",
      "31666  This is the 2nd time we have tried 2 contact u...     1\n",
      "31667              Will Ã¼ b going to esplanade fr home?     0\n",
      "31668  Pity, * was in mood for that. So...any other s...     0\n",
      "31669  The guy did some bitching but I acted like i'd...     0\n",
      "31670                         Rofl. Its true to its name     0 \n",
      "\n",
      "Logistic Regression Results\n",
      "Accuracy: 0.9710785551907047\n",
      "Precision: 0.9687317358270018\n",
      "Recall: 0.96450392784405\n",
      "F1 score: 0.9666132089225835 \n",
      "\n",
      "MultinomialNB Results\n",
      "Accuracy: 0.9667845415508967\n",
      "Precision: 0.980909090909091\n",
      "Recall: 0.9418097177771312\n",
      "F1 score: 0.960961852456583 \n",
      "\n",
      "K-Means Clustering Results\n",
      "Silhouette Score: 0.9557094326672363\n",
      "V-Measure Score: 0.0024803918912773342 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_data('MergedDataCleaned.csv')\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(data)\n",
    "\n",
    "train_evaluate_lr(X_train, X_test, y_train, y_test)\n",
    "train_evaluate_mnb(X_train, X_test, y_train, y_test)\n",
    "train_evaluate_km(data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
